{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forest Type Multi-class Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Downloaded the dataset from UCI website : https://archive.ics.uci.edu/ml/datasets/covertype\n",
    "Thought it may be interesting to try and design a ML classification problem and try to predict the forest cover type. There are 4 distinct cover types in this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tammy/.virtualenvs/vision36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from os import path as osp\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/home/tammy/Downloads/Forest_types'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(osp.join(folder, 'training.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['class', 'b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'b8', 'b9',\n",
       "       'pred_minus_obs_H_b1', 'pred_minus_obs_H_b2', 'pred_minus_obs_H_b3',\n",
       "       'pred_minus_obs_H_b4', 'pred_minus_obs_H_b5', 'pred_minus_obs_H_b6',\n",
       "       'pred_minus_obs_H_b7', 'pred_minus_obs_H_b8', 'pred_minus_obs_H_b9',\n",
       "       'pred_minus_obs_S_b1', 'pred_minus_obs_S_b2', 'pred_minus_obs_S_b3',\n",
       "       'pred_minus_obs_S_b4', 'pred_minus_obs_S_b5', 'pred_minus_obs_S_b6',\n",
       "       'pred_minus_obs_S_b7', 'pred_minus_obs_S_b8', 'pred_minus_obs_S_b9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n",
    "all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(osp.join(folder, 'testing.csv'))\n",
    "dataset = tf.data.TextLineDataset(osp.join(folder, 'testing.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_norm = [x for x in all_data.columns if x!='class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing values in all feature columns\n",
    "all_data[cols_to_norm] = all_data[cols_to_norm].apply(lambda x: ((x-x.min())/x.max()-x.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b9</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_minus_obs_H_b9</th>\n",
       "      <th>pred_minus_obs_S_b1</th>\n",
       "      <th>pred_minus_obs_S_b2</th>\n",
       "      <th>pred_minus_obs_S_b3</th>\n",
       "      <th>pred_minus_obs_S_b4</th>\n",
       "      <th>pred_minus_obs_S_b5</th>\n",
       "      <th>pred_minus_obs_S_b6</th>\n",
       "      <th>pred_minus_obs_S_b7</th>\n",
       "      <th>pred_minus_obs_S_b8</th>\n",
       "      <th>pred_minus_obs_S_b9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d</td>\n",
       "      <td>-30.925234</td>\n",
       "      <td>-22.91875</td>\n",
       "      <td>-46.948980</td>\n",
       "      <td>-53.784884</td>\n",
       "      <td>-42.84</td>\n",
       "      <td>-82.869565</td>\n",
       "      <td>-41.633094</td>\n",
       "      <td>-18.904762</td>\n",
       "      <td>-44.868421</td>\n",
       "      <td>...</td>\n",
       "      <td>64.117161</td>\n",
       "      <td>35.784308</td>\n",
       "      <td>9.355377</td>\n",
       "      <td>11.858575</td>\n",
       "      <td>50.657234</td>\n",
       "      <td>3.755465</td>\n",
       "      <td>9.377208</td>\n",
       "      <td>37.311662</td>\n",
       "      <td>9.285158</td>\n",
       "      <td>11.211258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>h</td>\n",
       "      <td>-30.504673</td>\n",
       "      <td>-22.95625</td>\n",
       "      <td>-46.948980</td>\n",
       "      <td>-53.662791</td>\n",
       "      <td>-42.92</td>\n",
       "      <td>-82.891304</td>\n",
       "      <td>-41.640288</td>\n",
       "      <td>-18.916667</td>\n",
       "      <td>-44.850877</td>\n",
       "      <td>...</td>\n",
       "      <td>64.127599</td>\n",
       "      <td>36.201462</td>\n",
       "      <td>9.349759</td>\n",
       "      <td>11.882999</td>\n",
       "      <td>51.848723</td>\n",
       "      <td>3.642093</td>\n",
       "      <td>9.377208</td>\n",
       "      <td>37.063706</td>\n",
       "      <td>8.870000</td>\n",
       "      <td>10.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s</td>\n",
       "      <td>-30.794393</td>\n",
       "      <td>-22.98750</td>\n",
       "      <td>-46.989796</td>\n",
       "      <td>-53.738372</td>\n",
       "      <td>-42.92</td>\n",
       "      <td>-82.927536</td>\n",
       "      <td>-41.697842</td>\n",
       "      <td>-18.916667</td>\n",
       "      <td>-44.885965</td>\n",
       "      <td>...</td>\n",
       "      <td>64.211106</td>\n",
       "      <td>36.269688</td>\n",
       "      <td>9.362600</td>\n",
       "      <td>12.101452</td>\n",
       "      <td>52.412553</td>\n",
       "      <td>4.081047</td>\n",
       "      <td>9.755381</td>\n",
       "      <td>38.001035</td>\n",
       "      <td>9.409593</td>\n",
       "      <td>11.312670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s</td>\n",
       "      <td>-30.738318</td>\n",
       "      <td>-22.98125</td>\n",
       "      <td>-46.989796</td>\n",
       "      <td>-53.715116</td>\n",
       "      <td>-42.96</td>\n",
       "      <td>-82.934783</td>\n",
       "      <td>-41.712230</td>\n",
       "      <td>-18.928571</td>\n",
       "      <td>-44.903509</td>\n",
       "      <td>...</td>\n",
       "      <td>64.643257</td>\n",
       "      <td>36.688791</td>\n",
       "      <td>9.303210</td>\n",
       "      <td>11.870787</td>\n",
       "      <td>50.125319</td>\n",
       "      <td>3.540349</td>\n",
       "      <td>9.270609</td>\n",
       "      <td>36.058256</td>\n",
       "      <td>8.969548</td>\n",
       "      <td>10.832567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d</td>\n",
       "      <td>-30.757009</td>\n",
       "      <td>-22.83750</td>\n",
       "      <td>-46.903061</td>\n",
       "      <td>-53.715116</td>\n",
       "      <td>-42.79</td>\n",
       "      <td>-82.833333</td>\n",
       "      <td>-41.482014</td>\n",
       "      <td>-18.892857</td>\n",
       "      <td>-44.877193</td>\n",
       "      <td>...</td>\n",
       "      <td>64.056618</td>\n",
       "      <td>35.135185</td>\n",
       "      <td>9.374639</td>\n",
       "      <td>12.104166</td>\n",
       "      <td>49.215745</td>\n",
       "      <td>3.973488</td>\n",
       "      <td>9.549797</td>\n",
       "      <td>37.221744</td>\n",
       "      <td>9.563439</td>\n",
       "      <td>11.470565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class         b1        b2         b3         b4     b5         b6  \\\n",
       "0    d  -30.925234 -22.91875 -46.948980 -53.784884 -42.84 -82.869565   \n",
       "1    h  -30.504673 -22.95625 -46.948980 -53.662791 -42.92 -82.891304   \n",
       "2    s  -30.794393 -22.98750 -46.989796 -53.738372 -42.92 -82.927536   \n",
       "3    s  -30.738318 -22.98125 -46.989796 -53.715116 -42.96 -82.934783   \n",
       "4    d  -30.757009 -22.83750 -46.903061 -53.715116 -42.79 -82.833333   \n",
       "\n",
       "          b7         b8         b9         ...           pred_minus_obs_H_b9  \\\n",
       "0 -41.633094 -18.904762 -44.868421         ...                     64.117161   \n",
       "1 -41.640288 -18.916667 -44.850877         ...                     64.127599   \n",
       "2 -41.697842 -18.916667 -44.885965         ...                     64.211106   \n",
       "3 -41.712230 -18.928571 -44.903509         ...                     64.643257   \n",
       "4 -41.482014 -18.892857 -44.877193         ...                     64.056618   \n",
       "\n",
       "   pred_minus_obs_S_b1  pred_minus_obs_S_b2  pred_minus_obs_S_b3  \\\n",
       "0            35.784308             9.355377            11.858575   \n",
       "1            36.201462             9.349759            11.882999   \n",
       "2            36.269688             9.362600            12.101452   \n",
       "3            36.688791             9.303210            11.870787   \n",
       "4            35.135185             9.374639            12.104166   \n",
       "\n",
       "   pred_minus_obs_S_b4  pred_minus_obs_S_b5  pred_minus_obs_S_b6  \\\n",
       "0            50.657234             3.755465             9.377208   \n",
       "1            51.848723             3.642093             9.377208   \n",
       "2            52.412553             4.081047             9.755381   \n",
       "3            50.125319             3.540349             9.270609   \n",
       "4            49.215745             3.973488             9.549797   \n",
       "\n",
       "   pred_minus_obs_S_b7  pred_minus_obs_S_b8  pred_minus_obs_S_b9  \n",
       "0            37.311662             9.285158            11.211258  \n",
       "1            37.063706             8.870000            10.830000  \n",
       "2            38.001035             9.409593            11.312670  \n",
       "3            36.058256             8.969548            10.832567  \n",
       "4            37.221744             9.563439            11.470565  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics = cols_to_norm\n",
    "for i, col in enumerate(cols_to_norm):\n",
    "    numerics[i] = (tf.feature_column.numeric_column(col))\n",
    "\n",
    "b1 = tf.feature_column.numeric_column(\"b1\")\n",
    "b2 = tf.feature_column.numeric_column(\"b2\")\n",
    "feat_cols = [b1, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 0 0 1]\n",
      " ...\n",
      " [0 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "#full list of classes\n",
    "category_classes = all_data['class']\n",
    "category_classes = category_classes.reshape(category_classes.shape[0],1)\n",
    "#print(category_classes)\n",
    "#using a label encoder, and binarizer to convert all unique category_ids to have a column for each class \n",
    "le = preprocessing.LabelEncoder() \n",
    "lb = preprocessing.LabelBinarizer()\n",
    "\n",
    "le.fit(all_data['class'])\n",
    "y_encoded = le.transform(all_data['class'])\n",
    "\n",
    "lb.fit(y_encoded)\n",
    "labels = lb.transform(y_encoded)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_data = all_data.drop('class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "...     x_data, labels , test_size=0.33, random_state=42)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'b8', 'b9',\n",
       "       'pred_minus_obs_H_b1', 'pred_minus_obs_H_b2', 'pred_minus_obs_H_b3',\n",
       "       'pred_minus_obs_H_b4', 'pred_minus_obs_H_b5', 'pred_minus_obs_H_b6',\n",
       "       'pred_minus_obs_H_b7', 'pred_minus_obs_H_b8', 'pred_minus_obs_H_b9',\n",
       "       'pred_minus_obs_S_b1', 'pred_minus_obs_S_b2', 'pred_minus_obs_S_b3',\n",
       "       'pred_minus_obs_S_b4', 'pred_minus_obs_S_b5', 'pred_minus_obs_S_b6',\n",
       "       'pred_minus_obs_S_b7', 'pred_minus_obs_S_b8', 'pred_minus_obs_S_b9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(350, 27) (350, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 4 # number of classes\n",
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "            / predictions.shape[0])\n",
    "\n",
    "data = X_train.as_matrix().astype(np.float32)\n",
    "labels = np.array(y_train).astype(np.float32)\n",
    "\n",
    "feature_size = data.shape[1]\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    tf_train_dataset = tf.constant(data)\n",
    "    tf_train_labels = tf.constant(labels)\n",
    "Wr(logits=tf.matmul(tf_train_dataset, weights) + biases, \n",
    "                                                labels=tf_train_labels))\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(0.1).minimize(loss)\n",
    "    train_prediction = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:0 loss:208.791656 accuracy: 15.14\n",
      "step:10000 loss:4.296745 accuracy: 40.86\n",
      "step:20000 loss:0.747740 accuracy: 88.00\n",
      "step:30000 loss:0.763769 accuracy: 89.14\n",
      "step:40000 loss:0.734552 accuracy: 89.14\n",
      "step:50000 loss:0.722539 accuracy: 89.43\n",
      "step:60000 loss:1.053671 accuracy: 85.43\n",
      "step:70000 loss:4.751954 accuracy: 77.43\n",
      "step:80000 loss:0.731642 accuracy: 90.86\n",
      "step:90000 loss:0.747181 accuracy: 90.86\n",
      "step:100000 loss:0.716342 accuracy: 90.86\n",
      "[[8.5926259e-11 9.9971443e-01 3.3371955e-10 2.8559662e-04]\n",
      " [4.0883716e-14 9.9995828e-01 2.3069710e-12 4.1705374e-05]\n",
      " [8.9249788e-08 1.5000348e-05 1.5001363e-07 9.9998474e-01]\n",
      " ...\n",
      " [9.8140121e-27 0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [3.2468302e-11 9.1154603e-31 1.0000000e+00 5.3647388e-30]\n",
      " [7.4006995e-11 9.9894470e-01 4.7564589e-13 1.0552674e-03]] [[0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    for step in range(100001):\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction])\n",
    "        if step % 10000 == 0:\n",
    "            print('step:{} loss:{:.6f} accuracy: {:.2f}'.format(\n",
    "                    step, l, accuracy(predictions, labels)))\n",
    "print(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
